{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries\n",
    "\n",
    "import time\n",
    "import re\n",
    "from multiprocessing import Pool, cpu_count   \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the books\n",
    "def load_text_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()  # Read file content \n",
    "    return text\n",
    "\n",
    "# Example usage\n",
    "A_Journey = load_text_file(\"A Journey to the Centre of the Earth.txt\")\n",
    "Around_The_World = load_text_file(\"Around the World in Eighty Days.txt\")\n",
    "Twenty_Thousand = load_text_file(\"Twenty Thousand Leagues under the Sea.txt\")\n",
    "\n",
    "# Put them in a list and create an empty list for storing the cleaned books\n",
    "books = [A_Journey, Around_The_World, Twenty_Thousand]\n",
    "cleaned_books = []\n",
    "\n",
    "# Split the texts in the books into sentences for smaller chunks of data and store them in the list\n",
    "\n",
    "for book in books:\n",
    "    book = book.replace('!', '.').replace('?', '.')\n",
    "    book = book.split('.')\n",
    "    cleaned_books.append(book)\n",
    "    \n",
    "# Use list comprehension to create one list with all the cleaned chunks from all books\n",
    "cleaned_chunks = [chunk for book in cleaned_books for chunk in book]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Misra-Gries Algorithm for Word Count\n",
    "def misra_gries_word_count(words, k):\n",
    "    \"\"\"\n",
    "    Misra-Gries algorithm to count word frequencies approximately.\n",
    "\n",
    "    :param words: List of words to process\n",
    "    :param k: Parameter determining the number of counters (frequency threshold)\n",
    "    :return: Approximate word counts as a dictionary\n",
    "    \"\"\"\n",
    "\n",
    "    counters = {}\n",
    "\n",
    "    # First pass: count words with a maximum of k-1 counters\n",
    "    for word in words:\n",
    "        if word in counters:\n",
    "            counters[word] += 1\n",
    "        elif len(counters) < k - 1:\n",
    "            counters[word] = 1\n",
    "        else:\n",
    "            # Decrement all counters if a new word can't be added\n",
    "            for key in list(counters.keys()):\n",
    "                counters[key] -= 1\n",
    "                if counters[key] == 0:\n",
    "                    del counters[key]\n",
    "\n",
    "    # Second pass: refine the counts for the words in the counters\n",
    "    refined_counts = {word: 0 for word in counters}\n",
    "    for word in words:\n",
    "        if word in refined_counts:\n",
    "            refined_counts[word] += 1\n",
    "\n",
    "    return refined_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for splitting each chunk into words in the parallel_wordcount function\n",
    "def split_chunk(chunk):\n",
    "    words = chunk.split()  \n",
    "    return words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for processing the cunks for the Misra-Gries algortihm\n",
    "# Needs to be defines like this so that eac core can use this function, can't be a lambda function\n",
    "def process_chunk_for_misra_gries(chunk, k):\n",
    "    return misra_gries_word_count(split_chunk(chunk), k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parallel MapReduce implementation\n",
    "def parallel_wordcount(text_chunks):\n",
    "    # Number of slots for Misra-Gries\n",
    "    k = 100\n",
    "    # Multi processing pool is created \n",
    "    with Pool(cpu_count()) as pool:    \n",
    "        word_counts = pool.map(\n",
    "            # Process chunks into words for misra-gries so it can count the words\n",
    "            process_chunk_for_misra_gries,\n",
    "            #using starmap for passing multiple arguments to the function  \n",
    "            # Chunk is the peice of text that is processed\n",
    "            # k is the number of counters for misra-gries\n",
    "            # Unpacks each tuple and passes them to each worker process which executes misra-gries\n",
    "            [(chunk, k) for chunk in text_chunks]\n",
    "        )\n",
    "    \n",
    "    return word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance counter for parallel misra-gries function\n",
    "start_time = time.perf_counter()\n",
    "\n",
    "parallel_counts = parallel_wordcount(cleaned_chunks)\n",
    "\n",
    "# Calculate duration\n",
    "parallel_duration = time.perf_counter() - start_time\n",
    "\n",
    "# Display results\n",
    "print(\"Parallel Word Count (Misra-Gries Algorithm):\")\n",
    "print(parallel_counts)\n",
    "print(f\"Parallel Duration: {parallel_duration:.6f} seconds\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
